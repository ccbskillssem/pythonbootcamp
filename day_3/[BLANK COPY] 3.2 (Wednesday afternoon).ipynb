{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vS2tF7uXaJJM"
      },
      "source": [
        "# More about data exploration\n",
        "\n",
        "Now that we have our data imported and cleaned, we can move on to summarizing and otherwise examining our data. Again, **do not try to memorize everything, you have access to a cheat sheet!**\n",
        "\n",
        "<font color = '#ed865c' size = 4>**Make sure to press the play button to run the cell below: this will re-load the datasets and functions that we worked on during the last section.**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4c4RG3hVMNl",
        "outputId": "bea5196d-2056-40e1-b5cf-f861b3df52a9"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "# we hid the contents of this cell because there's a lot going on in here\n",
        "# you can re-hide this cell by clicking on View -> Show/hide code\n",
        "\n",
        "!git clone https://github.com/ccbskillssem/pythonbootcamp.git\n",
        "import numpy as np\n",
        "\n",
        "### load and clean datasets ###\n",
        "animals2 = np.genfromtxt('/content/pythonbootcamp/day_3/Animals2.csv',\n",
        "              delimiter=',')\n",
        "animals2 = animals2[:, ~np.isnan(animals2).all(axis = 0)][~np.isnan(animals2).all(axis = 1), :]\n",
        "airquality = np.genfromtxt('/content/pythonbootcamp/day_3/airquality.csv',\n",
        "              delimiter=',')\n",
        "airquality = airquality[:, ~np.isnan(airquality).all(axis = 0)][~np.isnan(airquality).all(axis = 1), :]\n",
        "nan_inds = np.where(np.isnan(airquality))\n",
        "airquality[nan_inds] = np.take(np.nanmean(airquality, axis = 0), nan_inds[1])\n",
        "\n",
        "### load in sample solution for clean_data() ###\n",
        "def clean_data(data_array):\n",
        "  nan_map = np.isnan(data_array)\n",
        "\n",
        "  data_array = data_array[:, ~nan_map.all(axis = 0)]\n",
        "  data_array = data_array[~nan_map.all(axis = 1), :]\n",
        "  return data_array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nsz1KLq_URBP"
      },
      "source": [
        "## Examining attributes\n",
        "\n",
        "<font color = '#ed865c' size = 4>**Make sure to run the cell above before you begin: this will re-load the datasets and functions that we worked on during the last section.**</font>\n",
        "\n",
        "As we discussed yesterday, arrays have *attributes* that describe key characteristics of the array at hand. Let's take a look at the attributes of the `animals2` array, just to make sure that we have the right number of columns and rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ngf-3XiJayyE",
        "outputId": "10f42dab-ec42-4492-e7a0-7285bb32184d"
      },
      "outputs": [],
      "source": [
        "print(animals2.shape)\n",
        "print(animals2.size)\n",
        "print(animals2.ndim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Qbt9mtA8BtS"
      },
      "source": [
        "Everything looks to be in order: based on the background information about `animals2`, we know that there should be 65 rows (species) and two columns.\n",
        "\n",
        "## Heads and tails\n",
        "\n",
        "One good place to start is by simply examining the content of the data. As we saw earlier, calling `animals2` directly results in the entire dataset being shown in the output. However, it can be visually difficult to parse all 65 rows at once: in most cases, slicing a small number of rows will suffice for examining the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYaK4vqtKGuJ",
        "outputId": "0fefd389-fbcb-4aac-bf54-11f57cfa4715"
      },
      "outputs": [],
      "source": [
        "# let's slice the first ten rows of animals2\n",
        "animals2[:10,:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "He8JF9kRJphI"
      },
      "source": [
        "Good! This is a simple way for us to inspect a small, ordered section of the data: one row after another, for ten rows. This is described as viewing the **head** of our dataset.\n",
        "\n",
        "Similarly, taking a small number of rows from the end of your dataset is described as viewing the **tail** of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYj6D49USD2k",
        "outputId": "5f8ee733-5b9c-4423-e670-d58106a0a1de"
      },
      "outputs": [],
      "source": [
        "# try it out:\n",
        "# slice the *last* 10 rows of animals2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEkqoZE5DzYa"
      },
      "source": [
        "## Summarizing values\n",
        "\n",
        "Finally, we can generate some simple summary values. We've already taught you the following functions/methods that describe summary values of an array:\n",
        "* `np.min()` / `.min()`\n",
        "* `np.max()` / `.max()`\n",
        "* `np.mean()` / `.mean()`\n",
        "* `np.std()` / `.std()`\n",
        "* `np.var()` / `.var()`\n",
        "* `np.median()` (no method equivalent, for reasons unknown to us...)\n",
        "\n",
        "It's important to keep in mind that these summary functions/methods need a specific axis parameter to guide their operation: a row-wise mean will be different than a column-wise mean.\n",
        "\n",
        "* `0` indicates a column-wise operation.\n",
        "* `1` indicates a row-wise operation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cGCSry7kYBY",
        "outputId": "ff122bf4-3af9-43c1-bf5b-19b623a7a515"
      },
      "outputs": [],
      "source": [
        "# try it out:\n",
        "# calculate the column-wise means of animals2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmY-LHPsCJXF"
      },
      "source": [
        "These last four functions are slightly more advanced in their scope. We've summarized their main inputs and functions, but they do offer additional options that may be useful to you in the future. You can view these options in the docs.\n",
        "* `np.unique()`: Takes an array and returns a sorted copy of unique values. [[docs]](https://numpy.org/doc/stable/reference/generated/numpy.unique.html)\n",
        "* `np.histogram()`: Takes an array of values and returns a tuple of two arrays: the first array describes bin count, and the second array gives left-hand bin boundaries. [[docs]](https://numpy.org/doc/stable/reference/generated/numpy.histogram.html)\n",
        "  * You can explicitly specify desired bin boundaries using the `bins` input.\n",
        "* `np.percentile()`: Takes in an array and a percentile value (float, `0.0`-`100.0`), returning the value of the array that demarcates the given percentile value. [[docs]](https://numpy.org/doc/stable/reference/generated/numpy.percentile.html)\n",
        "* `np.quantile()`: Takes in an array and a quantile value (float, `0.0`-`1.0`), returning the value of the array that demarcates the given quantile value. [[docs]](https://numpy.org/doc/stable/reference/generated/numpy.quantile.html)\n",
        "\n",
        "We'll show you how these work using the `airquality` dataset. We've provided the columns again for your convenience:\n",
        "\n",
        "| Index  | Description                   |\n",
        "|--------|-------------------------------|\n",
        "| 0      | Ozone (ppb)                   |\n",
        "| 1      | Solar radiation (Langeleys)   |\n",
        "| 2      | Wind (mph)                    |\n",
        "| 3      | Temperature (degrees F)       |\n",
        "| 4      | Month (`1`-`12`)              |\n",
        "| 5      | Day of month (`1`-`31`)       |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVPF3JWbCEFW",
        "outputId": "b2ad5072-9c75-4ad3-d54e-91454b4d9fd8"
      },
      "outputs": [],
      "source": [
        "# using np.histogram() to generate bin count and intervals for\n",
        "# temperature values in airquality\n",
        "\n",
        "np.histogram(airquality[:,3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaFk0jARDheh",
        "outputId": "0e7afe82-833c-4984-c46c-68812917bb37"
      },
      "outputs": [],
      "source": [
        "# creating bins from the minimum temp to the maximum temp in 5 degree intervals\n",
        "temp_bins = np.arange(airquality[:,3].min(), airquality[:,3].max() + 5, 5)\n",
        "temp_bins"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNi5WU8sF3Sj",
        "outputId": "2e0c3199-25b5-44e8-b400-bd4455e42ff0"
      },
      "outputs": [],
      "source": [
        "# specifying temp_bins in np.histogram()\n",
        "np.histogram(airquality[:,3], bins = temp_bins)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laeHXxpC9AV6"
      },
      "source": [
        "## Very, very simple plots\n",
        "\n",
        "Plots can be a useful tool in data exploration: sometimes it's easier to identify patterns in data once it's been visualized.\n",
        "\n",
        "Today, we'll introduce you to some very simple plotting functions that you can use to explore your data. We'll use a popular package called `matplotlib`, which contains a collection of useful MATLAB-like plotting functions (`pyplot`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptPVqnP68_mT"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt # the alias is plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mq_RLdzK97mk"
      },
      "source": [
        "For today's purposes, we'll only introduce you to three simple `pyplot` functions and their key functionality.\n",
        "* `plt.hist()`: Takes in an array of values to generate a basic histogram plot.\n",
        "  * Can be used to visualize the distribution of values in a single column.\n",
        "  * You can explicitly specify desired bin boundaries using the `bins` input.\n",
        "* `plt.scatter()`: Takes in two arrays of values and generates a scatter plot.\n",
        "  * Can be used to visualize the relationship between values in two columns.\n",
        "* `plt.violinplot()`: Takes in a 2D array of values and plots a series of \"violins\".\n",
        "  * Can be used to visualize the distribution of values in *multiple* columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "26vlWUV6vmfd",
        "outputId": "c10e2efc-30b8-49af-b9e8-cc117fea89d5"
      },
      "outputs": [],
      "source": [
        "# creating a histogram of temperatures\n",
        "\n",
        "plt.hist(airquality[:,3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "l3Nn8B7XAOpK",
        "outputId": "a393b22a-a0c4-466b-a92d-2bd82755aa78"
      },
      "outputs": [],
      "source": [
        "# creating a histogram of temperatures using temp_bins\n",
        "\n",
        "plt.hist(airquality[:,3], bins = temp_bins)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "pv2YA4iDIVBz",
        "outputId": "27734a11-3951-4b84-cbd9-0142e257d3a7"
      },
      "outputs": [],
      "source": [
        "# visualizing temperature ranges by month\n",
        "\n",
        "plt.scatter(airquality[:,4], airquality[:,3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "id": "6fyUfpgnQxrl",
        "outputId": "5026bb98-439e-4a66-b5b9-5d82f8f9cc5c"
      },
      "outputs": [],
      "source": [
        "# visualize the distribution of values in all the columns.\n",
        "\n",
        "plt.violinplot(airquality)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0goybhJLCBt"
      },
      "source": [
        "As you can see, these plots are quite rudimentary, but they get the job done for data exploration. We'll explore greater `pyplot` functionality on Friday."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXknmaKG1F-i"
      },
      "source": [
        "# Mini-project: Exploring health data\n",
        "\n",
        "That's the last of the `numpy` techniques that we'll cover in this bootcamp!\n",
        "\n",
        "To cap things off, we're going to embark on a mini-project that will require you to use the skills you've learned so far. We've provided two project options:\n",
        "\n",
        "1. `badhealth`, a dataset describing healthcare habits of individuals and their self-reported health status. (Recommended)\n",
        "2. `hepatocellular`, a dataset from a journal article exploring gene expression biomarkers in cancer prognosis.\n",
        "\n",
        "We recommend that you start with `badhealth` and work on `hepatocellular` if you have extra time.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDHjEB7nPbIA"
      },
      "source": [
        "## `badhealth` dataset\n",
        "\n",
        "Our first dataset is the `badhealth` dataset. This dataset originates from a 1998 German health study of 1,127 individuals and their healthcare habits. [[source]](https://vincentarelbundock.github.io/Rdatasets/doc/COUNT/badhealth.html)\n",
        "\n",
        "Here are the descriptions and indices of columns in `badhealth`.\n",
        "\n",
        "| Index  | Description                   |\n",
        "|--------|-------------------------------|\n",
        "| 0      | Recorded # of doctor visits   |\n",
        "| 1      | Reported health status:<br>`0`: health, `1`: bad health   |\n",
        "| 2      | Age of patient (years)        |\n",
        "\n",
        "Using the following file path, import the `badhealth` dataset to a variable (also called `badhealth`). Slice and print the first 10 rows of the dataset.\n",
        "\n",
        "```\n",
        "'/content/pythonbootcamp/day_3/badhealth.csv'\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dDq4-QpPqtO",
        "outputId": "415c378d-77a2-412d-a85c-b99dd54f327e"
      },
      "outputs": [],
      "source": [
        "### use this cell to import and view the head of the data ###\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNB_U2mkPTbC"
      },
      "source": [
        "Next, use `clean_data()` to clean `badhealth`. There shouldn't be any interspersed `nan` values, but make sure to check anyway to practice your `nan`-detection routine!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dhi8pa5SPoVT",
        "outputId": "17f4be0d-0f3b-4338-f719-d959df33e2aa"
      },
      "outputs": [],
      "source": [
        "### write your code below ###\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXf0uY36MuSB"
      },
      "source": [
        "Let's consider some of the key summary values that we might want to identify in our dataset, such as mean and median values.\n",
        "\n",
        "Write a function called `summary_values()` that takes an array and returns a dictionary containing:\n",
        "* The number of elements in the array, with the key value `'count'`.\n",
        "* Column-wise minimum values, with the key value `'mins'`\n",
        "* Column-wise maximum values, with the key value `'maxs'`\n",
        "* Column-wise means, with the key value `'means'`\n",
        "* Column-wise medians, with the key value `'medians'`\n",
        "* Column-wise standard deviations, with the key value `'stdevs'`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3opBMcq1SfWZ"
      },
      "outputs": [],
      "source": [
        "### write your code below ###\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFUxkBPrM1lD"
      },
      "source": [
        "Next, using `summary_values()`, find the specified summaries of all columns in `badhealth`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78jwq6vjdVUM",
        "outputId": "edca4fbf-e080-4acc-e6c8-69a6532a52e7"
      },
      "outputs": [],
      "source": [
        "### write your code below ###\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzU_ljjUdZG1"
      },
      "source": [
        "Good! Let's try out more of the techniques we learned about earlier, such as percentiles and histograms.\n",
        "\n",
        "Below, use `np.histogram()` to generate a histogram of individual ages in `badhealth` using 5 year-intervals from the min to max age (inclusive of max age). Assign the intervals to a variable called `age_bins`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9CYu9hF-uU7",
        "outputId": "28b538cf-ce69-4cf8-f7f2-5cadb92e188a"
      },
      "outputs": [],
      "source": [
        "### write your code below ###\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgrxQjJvewgw"
      },
      "source": [
        "When you're done, try using `plt.hist()` to plot the histogram of ages, defined by `age_bins`: they should yield the same values as `np.histogram()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "EAkZtblfe5JI",
        "outputId": "8772df78-dc2b-4934-b2dd-f13c44e67e05"
      },
      "outputs": [],
      "source": [
        "### write your code below ###\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zgndnmoG0iA"
      },
      "source": [
        "Repeat the above process to generate the histogram and histogram plot of individuals' doctor visits. Save the 5-visit interval bins to a new variable called `visit_bins`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "RS12Ds3kHJV8",
        "outputId": "e8282c02-202e-4b92-cdf4-8568a54b13f9"
      },
      "outputs": [],
      "source": [
        "### write your code below ###\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba1l7wEOdOgd"
      },
      "source": [
        "What percentile range corresponds to 30 or more visits? Try out different values with `np.percentile()` to find out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgGdRLT38mzV",
        "outputId": "6fea1cd6-39df-4e48-9a26-acf76dc77f2b"
      },
      "outputs": [],
      "source": [
        "### write your code below ###\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJmmUHXVIEY4"
      },
      "source": [
        "Is there a difference in the age distribution of individuals who *never* visit the doctor, versus individuals who *frequently* visit the doctor?\n",
        "\n",
        "1.   `never_visit` for never-visiting individuals, or individuals with zero visits.\n",
        "2.   `frequent_visit` for frequently-visiting individuals, or individuals who visit more than 95% of other people (95+ percentile)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "252OAIvbIfVk"
      },
      "outputs": [],
      "source": [
        "### write your code below ###\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxSGQilQNo0K"
      },
      "source": [
        "Use `summary_values()` to examine the ages of each group. How many individuals are in each group? Does there seem to be a difference in the average/median age?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKZOYlBhNpem",
        "outputId": "c81ba4e5-bba9-44e1-d6c2-e0fffb2a281a"
      },
      "outputs": [],
      "source": [
        "### write your code below ###\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EulZFWUbdJud"
      },
      "source": [
        "Finally, plot age histograms for both groups using `age_bins`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "IZoFDJOG_5qJ",
        "outputId": "e19c92d5-64a6-4ca5-dd8a-88ed380ee08b"
      },
      "outputs": [],
      "source": [
        "# age histogram for never_visit\n",
        "### write your code below ###\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "j1CF22XOOmko",
        "outputId": "09fbd70e-c11f-456d-8d02-731d4a61a7dc"
      },
      "outputs": [],
      "source": [
        "# age histogram for frequent_visit\n",
        "### write your code below ###\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4g4_fm8PZub"
      },
      "source": [
        "Are there other explorations you can think of, or better ways to plot the relationship between variables? If time permits, share your own useful explorations or visualizations!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-uWZVMGgrEs"
      },
      "source": [
        "## `hepatocellular` dataset\n",
        "\n",
        "The `hepatocellular` dataset describes clinical metrics and biomarkers sampled in patients with hepatocellular carcinoma.\n",
        "\n",
        "> This dataset was obtained from this [source](https://vincentarelbundock.github.io/Rdatasets/doc/asaur/hepatoCellular.html), and originates from [Li et al. 2014: CXCL17 Expression Predicts Poor Prognosis and Correlates with Adverse Immune Infiltration in Hepatocellular Carcinoma](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0110064).\n",
        "\n",
        "`hepatocellular` contains significantly more columns than `badhealth`, spanning 48 variables for 227 individuals.\n",
        "\n",
        "Columns are listed in the following order: we've provided the 0-index of all columns for your convenience. All column values are encoded numerically.\n",
        "\n",
        "| Index   |      Description     | Index   |        Description       |  Index  |      Description      |  Index   |      Description    |\n",
        "| ------- | ---------------------| ------- | -------------------------| ------- | ----------------------| -------- | --------------------|\n",
        "| 0       | Patient ID number    | 12      | Capsulation              | 24      | CD8T                  | 36       | CD20NR              |\n",
        "| 1       | Age                  | 13      | TNM                      | 25      | CD8N                  | 37       | CD57NR              |\n",
        "| 2       | Sex                  | 14      | BCLC                     | 26      | CD20T                 | 38       | CD15NR              |\n",
        "| 3       | HBsAg                | 15      | Overall survival         | 27      | CD20N                 | 39       | CD68NR              |\n",
        "| 4       | Cirrhosis status     | 16      | Death                    | 28      | CD57T                 | 40       | CD4TR               |\n",
        "| 5       | ALT                  | 17      | Recurrence-free survival | 29      | CD57N                 | 41       | CD8TR               |\n",
        "| 6       | AST                  | 18      | Recurrence               | 30      | CD15T                 | 42       | CD20TR              |\n",
        "| 7       | AFP                  | 19      | CXCL17T                  | 31      | CD15N                 | 43       | CD57TR              |\n",
        "| 8       | Tumor size           | 20      | CXCL17P                  | 32      | CD68T                 | 44       | CD15TR              |\n",
        "| 9       | Tumor differentiation| 21      | CXCL17N                  | 33      | CD68N                 | 45       | CD68TR              |\n",
        "| 10      | Vascular invasion    | 22      | CD4T                     | 34      | CD4NR                 | 46       | Ki67                |\n",
        "| 11      | Tumor multiplicity   | 23      | CD4N                     | 35      | CD8NR                 | 47       | CD34                |\n",
        "\n",
        "That's a lot of columns, but have no fear – we're only going to have you take a look at a couple of them, and you don't need to know what the biological function of the biomarkers are (but we won't stop you from looking them up!)\n",
        "\n",
        "Just as before, start by importing the data from the following file path, then cleaning all-`nan` rows/columns using `clean_data()`.\n",
        "\n",
        "`'/content/pythonbootcamp/day_3/hepatoCellular.csv'`\n",
        "\n",
        "Assign this to a variable called `hepatocellular`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufksqFn-hCyv",
        "outputId": "245a9558-063e-453d-8bf3-bbb8039e8fc5"
      },
      "outputs": [],
      "source": [
        "### use this cell to import and clean the data ###\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLMUcoJbTLct"
      },
      "source": [
        "Check for remaining `nan` values by column. Which columns still have `nan` values?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7HrYPAhTAi_",
        "outputId": "41a29954-09b4-40ca-8bb4-bb0a7e2165fc"
      },
      "outputs": [],
      "source": [
        "### write your code below ###\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JwVI8cEbSa4"
      },
      "source": [
        "For our purposes, we'll only be examining columns without `nan` values. The `hepatocellular` dataset has data for three measurements of `CXCL17` gene expression:\n",
        "* `CXCL17T`, Index 19: Intratumoral gene expression (measured within tumoral tissue).\n",
        "* `CXCL17P`, Index 20: Peritumoral gene expression (measured adjacent to tumoral tissue).\n",
        "* `CXCL17N`, Index 21: Non-tumoral gene expression.\n",
        "\n",
        "Recall the simple `pyplot` functions we taught you about earlier: which one is suitable for visualizing all three measurements of *CXCL17* expression? Use this function to visualize gene expression across all three measurements for all patients in `hepatocellular`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "YQBpiQX_b5fm",
        "outputId": "29e04c76-36d8-43f3-fa71-edb1684a41e7"
      },
      "outputs": [],
      "source": [
        "# visualize the measurements of CXCL17 expression\n",
        "### write your code below ###\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaGOjdBadIHL"
      },
      "source": [
        "Take a moment to examine the range and distribution of each measurement: what does the spread of the values look like?\n",
        "\n",
        "In the paper discussion, the authors posit that high peritumoral and intratumoral *CXCL17* expression is predictive of carcinoma prognosis. Let's see if we can see the same trend, using very basic data exploration.\n",
        "\n",
        "* Find the median values for peritumoral and intratumoral *CXCL17* expression.\n",
        "* Create two new subsets: `low_exp`, for patients with below-median expression for both peri- and intratumoral expression, and `high_exp`, for patients with above-median expression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dsGOa0e-dom1"
      },
      "outputs": [],
      "source": [
        "### write your code below ###\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5OlqSl9e_MF"
      },
      "source": [
        "Next, re-examine the distribution of all three *CXCL17T* measurements: this time, create one plot for `low_exp` and `high_exp`. Do you notice any trends or associations?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "v2rYXTrvewTH",
        "outputId": "dc9f05d2-7e99-4a57-80e7-fbe2d60ee371"
      },
      "outputs": [],
      "source": [
        "# plot distributions of CXCL17 for low_exp\n",
        "### write your code below ###\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "hucGeVUde0nz",
        "outputId": "e9f6784c-e78d-4183-a6b5-1445320ed280"
      },
      "outputs": [],
      "source": [
        "# plot distributions of CXCL17 for high_exp\n",
        "### write your code below ###\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T85sdpvbfZWy"
      },
      "source": [
        "Next, let's look at patient prognosis. There are several measures of patient outcomes in the dataset, but we'll focus on just two: patient death (Index 16) and recurrence-free survival (Index 17).\n",
        "\n",
        "As we mentioned earlier, all of the columns in `hepatocellular` are numeric. Patient death is encoded as either a `0` or a `1`.\n",
        "* `0` indicates that the patient did not die.\n",
        "* `1` indicates patient death.\n",
        "\n",
        "Below, calculate the relative proportion of patients that died in `low_exp` and `high_exp`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CY_6IiCXfw_b",
        "outputId": "5b522f95-85fc-46fd-ac2e-3a74512f5633"
      },
      "outputs": [],
      "source": [
        "### write your code below ###\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUVx8iuel3U6"
      },
      "source": [
        "Next, let's examine recurrence-free survival. The clinical definition of recurrence-free survival is the number of days between the dates of sample biopsy and cancer recurrence, or the date from sample biopsy to last follow-up if no recurrence was observed.\n",
        "\n",
        "Below, calculate the summary values and plot the distribution of recurrence-free survival intervals for patients in both groups *on the same histogram plot*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owwj9R9Xm1Go",
        "outputId": "ef0c44f3-133b-4597-b573-53abebf7f326"
      },
      "outputs": [],
      "source": [
        "# calculate summary values here\n",
        "### write your code below ###\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "nRr_mxLCkRwy",
        "outputId": "2de7d4d8-5ce1-42db-f1ec-e30aa8c5b887"
      },
      "outputs": [],
      "source": [
        "# plot the distribution here\n",
        "### write your code below ###\n",
        "\n",
        "# hint: you can plot *two* histogram distributions on the same plot\n",
        "# if you provide a list of arrays\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pd0ye54bn4Ci"
      },
      "source": [
        "That's it for `hepatocellular`! If you've finished early, you can review the paper manuscript and work on executing some more explorations according to the author's findings. If time permits, we'll ask people to share their results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ge7GlvSYA43O"
      },
      "source": [
        "# Introduction to Pandas\n",
        "\n",
        "That's about it for today! We hope that you enjoyed putting your skills to the test.\n",
        "\n",
        "Tomorrow, we'll embark on our last full day of lecture content that will discuss data exploration and preliminary analysis. We'll be working with a package called `pandas`, which is a package that extends the array infrastructure provided by `numpy`.\n",
        "\n",
        "> *Another package already?!* 😱<br>\n",
        "Have no fear: all of the conceptual material we covered with `numpy` arrays is transferable to `pandas`. In fact, `pandas` takes care of many of the techniques that were fairly clunky for us to perform with `numpy`, and most people find `pandas` a little more intuitive to work with. We're only going to preview our forthcoming work with `pandas` today.\n",
        "\n",
        "Let's think all the way back to when we first introduced `numpy`: recall that arrays *do* have their limitations. For one, arrays can't contain multiple types. This can be troublesome for scientific data that can't be stored in solely numeric form. Thus, we turn to `pandas`.\n",
        "\n",
        "Like `numpy`, `pandas` is imported with a shorthand **alias** (`pd`), which is used as the prefix for any functions imported via `pandas`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5FHiVmvEI9F"
      },
      "outputs": [],
      "source": [
        "# try it out: import pandas with its alias\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYMrGHlyS78m"
      },
      "source": [
        "## DataFrames versus arrays\n",
        "\n",
        "`pandas` is a great tool for data manipulation and analysis in Python because of the infrastructure it provides for complex tabular data. Just as `numpy` introduced the array, `pandas` introduces the **DataFrame** (a term familiar to those of you coming from R).\n",
        "\n",
        "DataFrames and arrays are quite similar in many aspects. For one, they can both be used to store rectangular data (rows and columns), and they're both useful for performing vectorized operations. However, DataFrames have several key functions that can make it easier to work with *labeled* data.\n",
        "\n",
        "1. **DataFrames allow mixed types.** Unlike with arrays, you can store strings, integers, numerics, etc. in the same DataFrame.\n",
        "2. **DataFrames supports row and column names**. You can index with row and column names! This can be handy if you know your sample/variable names by heart.\n",
        "3. **DataFrames support easy database-like operations**. Merging, joining, grouping, sorting on a column's values – all possible with `pandas` DataFrames!\n",
        "\n",
        "We'll teach you about the essential `pandas` functions and operations, but if you'd like to know *more* about what you can do with `pandas`, you can read the introduction on the `pandas` documentation [here](https://pandas.pydata.org/pandas-docs/stable/getting_started/overview.html).\n",
        "\n",
        "Let's take a quick look at some data using `pandas`. All of the operations we're showing you will be covered in tomorrow's lecture, so there's no need to commit all of it to memory right now."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYAqZ4rsEWns"
      },
      "source": [
        "We'll teach you about the essential `pandas` functions and operations, but if you'd like to know *more* about what you can do with `pandas`, you can read the introduction on the `pandas` documentation [here](https://pandas.pydata.org/pandas-docs/stable/getting_started/overview.html).\n",
        "\n",
        "Let's take a quick look at some data using `pandas`. All of the operations we're showing you will be covered in tomorrow's lecture, so there's no need to commit all of it to memory right now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "5aXdUo-6E50q",
        "outputId": "206a401a-1f08-4217-dc03-e5ccb69ae375"
      },
      "outputs": [],
      "source": [
        "# importing data\n",
        "\n",
        "airquality_df = pd.read_csv('/content/pythonbootcamp/day_3/airquality.csv').drop('Unnamed: 0', axis = 1)\n",
        "airquality_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-bgREA8RaxX"
      },
      "source": [
        "This is the `airquality` dataset we worked with earlier today, but imported into a `pandas` DataFrame. The first thing you'll notice is that the display of the data is quite different, compared to an array.\n",
        "\n",
        "Next, you'll probably notice that the columns in this table have names, and the rows have numbers: DataFrames operate using these **labels** as indices, rather than the strict numerical indices we've been using so far. This is *especially* useful for columns!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "NYKpaZAHSVBj",
        "outputId": "fe027788-1152-479a-c317-b23f81abe646"
      },
      "outputs": [],
      "source": [
        "hepatocellular_df = pd.read_csv('/content/pythonbootcamp/day_3/hepatoCellular.csv').drop('Unnamed: 0', axis = 1)\n",
        "hepatocellular_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lo3eHO5aSdjy"
      },
      "source": [
        "Look at all those columns! With DataFrames, you won't need to worry about constantly referring to index lists for datasets like `hepatocellular` that contain dozens of columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1v-ES7D1R8oJ",
        "outputId": "70d273d7-015d-41d7-8819-19c739fa5940"
      },
      "outputs": [],
      "source": [
        "# before, if we wanted CXCL17T expression\n",
        "hepatocellular[:,19]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5qtgiTFSEXl",
        "outputId": "9b411217-9260-431a-e4e1-41c5964c405e"
      },
      "outputs": [],
      "source": [
        "# if we want to examine CXCL17T expression in our DataFrame\n",
        "hepatocellular_df['CXCL17T']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_klT99sZSN5v"
      },
      "source": [
        "Hopefully this is starting to show you some of the motivation behind `pandas` and DataFrames! By the end of the week, you'll be well-prepared to use `numpy`, `pandas`, and `pyplot` to analyze *your* particular data. We'll have TAs on staff during the Friday afternoon session to discuss future directions for your Python analyses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtzY5548Qn0U"
      },
      "source": [
        "# [Optional] Saving your arrays to external files\n",
        "\n",
        "`numpy` also provides a utility function called `np.savetxt()` that saves arrays to external files. We won't be using it in the remainder of the bootcamp (`pandas` has superior file input/output functions for mixed-type data), but it may be useful if you work with solely numerical data.\n",
        "\n",
        "`np.savetxt()` takes three key inputs:\n",
        "1. A file name.\n",
        "2. The array of interest.\n",
        "3. A `delimiter` string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gV4tfZYfQnRp",
        "outputId": "0704c564-0793-4fef-9fe9-5cb1d78d835f"
      },
      "outputs": [],
      "source": [
        "# let's sample 5 random rows from airquality\n",
        "\n",
        "rng = np.random.default_rng(2023) # this time, using a seed value for reproducibility\n",
        "random_airquality = rng.choice(airquality, 5)\n",
        "random_airquality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zg77LO5nTNLt"
      },
      "outputs": [],
      "source": [
        "# now let's save random_airquality as a comma-separated value file\n",
        "np.savetxt('random_airquality.csv', random_airquality, delimiter = ',')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TPs58j-Tp3l"
      },
      "source": [
        "Go to the left hand panel of the Colab notebook and click on the folder icon at the bottom of the panel. This will bring you to Colab's `Files` menu. You should see a file called `random_airquality.csv`: if you hover over it and click the menu with three dots, you can obtain the file path (if you want to import it again) or download the file.\n",
        "___\n",
        "**CAUTION**: Files that you save while using Colab are not retained after you close the notebook, as they only exist in Colab's temporary **session storage**. If you generate files and wish to keep them, make sure to download your files (with the same three dots menu) before you exit Colab.\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ST-WXNFsPoD"
      },
      "source": [
        "# [Optional] Cloning files from GitHub\n",
        "\n",
        "> This section was first introduced in the morning session on `numpy`. We've copy-pasted it here for convenience.\n",
        "\n",
        "[GitHub](https://github.com/) is a website that hosts code and files for software development projects. It serves two major functions: backing up **codebases** (files with data and code that work together) and enabling collaboration between programmers/developers.\n",
        "\n",
        "We (your staff team) use GitHub as a **repository** for files that are used during PyCamp. We do this so that we have a stable copy of these files that stays out of \"I spilled coffee on my laptop the night before PyCamp\", or \"my laptop was ransomed for cryptocurrency\" territory. Moreover, if we accidentally delete a file from the repository, GitHub's **version control**  allows us to roll back the repository to a working version. Neat, right?\n",
        "\n",
        "The below command allows us to **clone** these files from the GitHub repository to our local runtime's session storage. This allows for us to skip the messy steps of trying to get everyone to download and re-upload the right data.\n",
        "\n",
        "```\n",
        "!git clone https://github.com/ccbskillssem/pythonbootcamp.git\n",
        "```\n",
        "\n",
        "The `!` operator is used to indicate *special commands* that would normally be run at a computer's **command line**, rather than in Python. This is akin to communicating with a computer (or in Colab, our runtime) directly to tell it that we want to download files using the given file path.\n",
        "\n",
        "The GitHub file path that you see above points to a single file called a `.git` file. This file does not contain all the data: rather, it provides directions to the GitHub repository of interest, and therefore all the files it contains. In this manner, we never have to worry about giving all the file paths to each file we want: we just pull all the files in the repository by giving its `.git` file path."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkHMnmrPUOlR"
      },
      "source": [
        "# [Optional] More methods for external data\n",
        "\n",
        "> This section was first introduced in yesterday's session on `numpy`. We've copy-pasted it here for convenience.\n",
        "\n",
        "This section describes the bare essentials of file uploads/downloads with Colab. For a more in-depth exploration, you can visit the official Google Colab notebook on data I/O [here](https://colab.research.google.com/notebooks/io.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nFgc5EnUwZW"
      },
      "source": [
        "## Loading data from your computer\n",
        "You can use Colab's `Files` menu to upload data from your own computer to Colab's temporary **session storage**. Session storage is reset each time the notebook runtime ends or is otherwise reset.\n",
        "\n",
        "Go to the left hand panel of the Colab notebook and click on the folder icon at the bottom of the panel. This will bring you to Colab's `Files` menu.\n",
        "\n",
        "Click on the leftmost icon underneath the `'Files'` title of the panel: it should appear as a piece of paper with an up arrow on it. Follow the prompts to upload your data of choice. Once your file is uploaded, you can access the file path by hovering over the file name, clicking on the three-dot menu, then selecting `Copy path`.\n",
        "\n",
        "___\n",
        "\n",
        "**CAUTION**: Files that you upload are NOT retained in the `Files` panel after you close the notebook or reset the runtime. If you would prefer to avoid the upload process, consider the next section on loading data from Google Drive.\n",
        "\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIs4S8UeVl1p"
      },
      "source": [
        "## Loading data from Google Drive\n",
        "Google Drive is an excellent cloud storage solution for data you wish to work with in Colab. Colab provides a simple solution for allowing you to access files from Google Drive in Colab: all you have to do is access the `Files` menu by clicking the folder icon on the left hand panel of the Colab notebook.\n",
        "\n",
        "Once you're in the `Files` menu, click on the third icon below the `'Files'` title: it should appear as a filled-in white folder with the Google Drive icon. Click this button to connect Google Drive to Colab: a pop-up should appear asking you to confirm that you wish to do this, and you may need to wait a few minutes while Google Drive loads.\n",
        "\n",
        "Once your Drive is mounted, you should see a new folder called `drive` in the `Files` menu. You can access the file path by hovering over the file name, clicking on the three-dot menu, then selecting `Copy path`."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
